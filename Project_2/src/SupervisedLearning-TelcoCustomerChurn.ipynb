{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f486c2f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Supervised Learning - Telco Customer Churn\n",
    "\n",
    "## Introduction\n",
    "* The main goal of this project is to build a model using different Supervised Learning algorithms using the dataset: *Sample Telco Customer Churn Dataset*.\n",
    "* After analyzing our dataset and applying these algorithms, we want our model to be able to predict if a customer is likely to be lost to a competitor.\n",
    "\n",
    "## Dataset\n",
    "* The dataset is composed by the following columns:\n",
    "    * customerID: A unique ID that identifies each customer.\n",
    "    * gender: The customer’s gender: Male (1), Female (0).\n",
    "    * SeniorCitizen: Indicates if the customer is 65 or older: No (0), Yes (1).\n",
    "    * Partner: Service contract is resold by the partner: No (0), Yes (1).\n",
    "    * Dependents: Indicates if the customer lives with any dependents: No (0), Yes (1).\n",
    "    * Tenure: Indicates the total amount of months that the customer has been with the company.\n",
    "    * PhoneService: Indicates if the customer subscribes to home phone service with the company: No (0), Yes (1).\n",
    "    * MultipleLines: Indicates if the customer subscribes to multiple telephone lines with the company: No (0), Yes (1).\n",
    "    * InternetService: Indicates if the customer subscribes to Internet service with the company: No (0), DSL (1), Fiber optic (2).\n",
    "    * OnlineSecurity: Indicates if the customer subscribes to an additional online security service provided by the company: No (0), Yes (1), NA (2).\n",
    "    * OnlineBackup: Indicates if the customer subscribes to an additional online backup service provided by the company: No (0), Yes (1), NA (2).\n",
    "    * DeviceProtection: Indicates if the customer subscribes to an additional device protection plan for their Internet equipment provided by the company: No (0), Yes (1), NA (2).\n",
    "    * TechSupport: Indicates if the customer subscribes to an additional technical support plan from the company with reduced wait times: No (0), Yes (1), NA (2).\n",
    "    * StreamingTV: Indicates if the customer uses their Internet service to stream television programing from a third party provider: No (0), Yes (1), NA (2). The company does not charge an additional fee for this service.\n",
    "    * StreamingMovies: Indicates if the customer uses their Internet service to stream movies from a third party provider: No (0), Yes (1), NA (2). The company does not charge an additional fee for this service.\n",
    "    * Contract: Indicates the customer’s current contract type: Month-to-Month (0), One Year (1), Two Year (2).\n",
    "    * PaperlessBilling: Indicates if the customer has chosen paperless billing: No (0), Yes (1).\n",
    "    * PaymentMethod: Indicates how the customer pays their bill: Bank transfer - automatic (0), Credit card - automatic (1), Electronic cheque (2), Mailed cheque (3).\n",
    "    * MonthlyCharges: Indicates the customer’s current total monthly charge for all their services from the company.\n",
    "    * TotalCharges: Indicates the customer’s total charges.\n",
    "    * Churn: Indicates if the customer churn or not: No (0), Yes (1).\n",
    "\n",
    "## Development\n",
    "* To predict likelihood of a costumer leaving the service, we used four different algorithms for our model: Decision Trees, Support Vector Regression (SVR), K-Nearest Neighbors and Neural Networks (Multi-layer Perceptron).\n",
    "* After making the predictions, a smaller sample of data is used in order to estimate how the models are expected to perform in general when used to make predictions on data not used during the training of these models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af75db57",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import preprocessing, linear_model, neighbors\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.colors import ListedColormap\n",
    "import time\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# import data\n",
    "churn_data = pd.read_csv('WA_Fn-UseC_-Telco-Customer-Churn_R2.csv')\n",
    "\n",
    "input_names = list(churn_data.columns)\n",
    "\n",
    "all_inputs = churn_data[input_names].values\n",
    "\n",
    "# set target data\n",
    "churn_target = churn_data.iloc[:,-1]\n",
    "\n",
    "# set feature data\n",
    "churn_data.drop([\"customerID\",\"Churn\"], axis=1, inplace=True)\n",
    "\n",
    "# set training and test variables\n",
    "X = np.array(churn_data)\n",
    "y = np.array(churn_target)\n",
    "\n",
    "# set variables for target and features\n",
    "features = list(churn_data)\n",
    "targets = list(churn_target)\n",
    "\n",
    "# divide data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 100)\n",
    "\n",
    "# set seaborn style and fontsize\n",
    "sb.set_style('ticks')\n",
    "sb.set_context('paper', font_scale=1.6)\n",
    "\n",
    "# data normalization\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Decision Trees - Gini criterion"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training time and accuracy - Gini"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#define the model\n",
    "clf_gini = DecisionTreeClassifier(criterion = \"gini\", max_depth = 3)\n",
    "\n",
    "# fit the model and time it\n",
    "start = time.time()\n",
    "\n",
    "clf_gini.fit(X_train, y_train)\n",
    "\n",
    "stop = time.time()\n",
    "\n",
    "training_gini = stop - start\n",
    "print(f\"Training: {training_gini} seconds\")\n",
    "\n",
    "# get predicted values\n",
    "y_pred_gini = clf_gini.predict(X_test)\n",
    "\n",
    "# get accuracy\n",
    "accuracy_gini = accuracy_score(y_test,y_pred_gini)*100\n",
    "print (f\"Accuracy : {accuracy_gini}%\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Feature Importance - Gini"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# get feature importance\n",
    "importances_gini = clf_gini.feature_importances_\n",
    "\n",
    "# summarize feature importance\n",
    "#for i,v in enumerate(importance):\n",
    "#    print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "\n",
    "# plot feature importance\n",
    "feat_importances_gini = pd.Series(importances_gini, index=churn_data.columns)\n",
    "feat_importances_gini.nlargest(7).plot(kind='barh')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Confusion Matrix - Gini"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plot confusion matrix\n",
    "confusion_matrix_gini = sb.heatmap(confusion_matrix(y_test, y_pred_gini),annot=True,cmap='Blues', fmt='g')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Classification Report - Gini"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plot classification report\n",
    "clf_report_gini = classification_report(y_test, \n",
    "                                   y_pred_gini,\n",
    "                                   output_dict=True)\n",
    "classification_report_gini = sb.heatmap(pd.DataFrame(clf_report_gini).iloc[:-1, :].T, annot=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Decision Tree plot - Gini"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plot decision tree\n",
    "plt.figure(figsize=(25,10))\n",
    "plot_tree_gini = plot_tree(clf_gini, \n",
    "              feature_names=features, \n",
    "              filled=True, \n",
    "              rounded=True, \n",
    "              fontsize=14)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Decision Trees - Entropy criterion"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training time and Accuracy - Entropy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#define the model\n",
    "clf_entropy = DecisionTreeClassifier(criterion = \"entropy\", max_depth = 3)\n",
    "\n",
    "# fit the model and time it\n",
    "start = time.time()\n",
    "\n",
    "clf_entropy.fit(X_train, y_train)\n",
    "\n",
    "stop = time.time()\n",
    "\n",
    "training_entropy = stop - start\n",
    "print(f\"Training: {training_entropy} seconds\")\n",
    "\n",
    "# get predicted values\n",
    "y_pred_entropy = clf_entropy.predict(X_test)\n",
    "\n",
    "# get accuracy\n",
    "accuracy_entropy = accuracy_score(y_test,y_pred_entropy)*100\n",
    "print (f\"Accuracy : {accuracy_entropy}%\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Feature Importance - Entropy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# get feature importance\n",
    "importances_entropy = clf_entropy.feature_importances_\n",
    "\n",
    "# summarize feature importance\n",
    "#for i,v in enumerate(importance):\n",
    "#    print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "\n",
    "# plot feature importance\n",
    "feat_importances_entropy = pd.Series(importances_entropy, index=churn_data.columns)\n",
    "feat_importances_entropy.nlargest(7).plot(kind='barh')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Confusion Matrix - Entropy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plot confusion matrix\n",
    "confusion_matrix_entropy = sb.heatmap(confusion_matrix(y_test, y_pred_entropy),annot=True,cmap='Blues', fmt='g')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Classification Report - Entropy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plot classification report\n",
    "clf_report_entropy = classification_report(y_test, \n",
    "                                   y_pred_entropy,\n",
    "                                   output_dict=True)\n",
    "classification_report_entropy = sb.heatmap(pd.DataFrame(clf_report_entropy).iloc[:-1, :].T, annot=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Decision Tree plot - Entropy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plot decision tree\n",
    "plt.figure(figsize=(25,10))\n",
    "plot_tree_entropy = plot_tree(clf_entropy, \n",
    "              feature_names=features, \n",
    "              filled=True, \n",
    "              rounded=True, \n",
    "              fontsize=14)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## K-Nearest Neighbor"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training time and Accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# initialize the class with the number of neighbours wanted\n",
    "clf_knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "#fit the model and time it\n",
    "start = time.time()\n",
    "\n",
    "clf_knn.fit(X_train, y_train)\n",
    "\n",
    "stop = time.time()\n",
    "\n",
    "training_knn = stop - start\n",
    "print(f\"Training: {training_knn} seconds\")\n",
    "print()\n",
    "\n",
    "# Validate the classifier on the testing set using classification accuracy\n",
    "clf_knn.score(X_train, y_train)\n",
    "\n",
    "# get predicted values\n",
    "y_pred_knn = clf_knn.predict(X_test)\n",
    "\n",
    "accuracy_knn = accuracy_score(y_test,y_pred_knn)*100\n",
    "print (f\"Accuracy: {accuracy_knn}%\")\n",
    "print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Confusion Matrix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plot confusion matrix\n",
    "confusion_matrix_knn = sb.heatmap(confusion_matrix(y_test, y_pred_knn),annot=True,cmap='Blues', fmt='g')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Classification Report"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plot classification report\n",
    "clf_report_knn = classification_report(y_test,\n",
    "                                   y_pred_knn,\n",
    "                                   output_dict=True)\n",
    "classification_report_knn = sb.heatmap(pd.DataFrame(clf_report_knn).iloc[:-1, :].T, annot=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Error rate for K value\n",
    "* We tried different number of neighbours in order to find out which one was less error-prone."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "error = []\n",
    "\n",
    "min = 1\n",
    "bestNeighbours = 0\n",
    "\n",
    "# Calculating error for K values between 1 and 40\n",
    "for i in range(1, 100):\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(X_train, y_train)\n",
    "    pred_i = knn.predict(X_test)\n",
    "    error.append(np.mean(pred_i != y_test))\n",
    "    if(min > np.mean(pred_i != y_test)):\n",
    "        min = np.mean(pred_i != y_test)\n",
    "        bestNeighbours = i\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(1, 100), error, color='red', linestyle='dashed', marker='o',\n",
    "         markerfacecolor='blue', markersize=10)\n",
    "plt.title('Error Rate K Value')\n",
    "plt.xlabel('K Value')\n",
    "plt.ylabel('Mean Error')\n",
    "\n",
    "print(f'Best number of neighbours: {bestNeighbours}' )\n",
    "print(f'Min error value: {min}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Testing different classifiers\n",
    "* We used different weights and algorithms in order to find out the best classifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "parameter_grid = {'n_neighbors': [50],\n",
    "                  'weights': ['uniform', 'distance'],\n",
    "                  'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']}\n",
    "\n",
    "grid_search = GridSearchCV(KNeighborsClassifier(),\n",
    "                           param_grid=parameter_grid,\n",
    "                           cv=10)\n",
    "\n",
    "all_inputs = churn_data.values\n",
    "all_labels = churn_target.values\n",
    "\n",
    "grid_search.fit(all_inputs, all_labels)\n",
    "print('Best score: {}'.format(grid_search.best_score_))\n",
    "print('Best parameters: {}'.format(grid_search.best_params_))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Best classifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_clf_knn = KNeighborsClassifier(algorithm='ball_tree', n_neighbors=50, weights='distance')\n",
    "\n",
    "# Train the classifier on the training set\n",
    "best_clf_knn.fit(X_train, y_train)\n",
    "best_predictions = best_clf_knn.predict(X_test)\n",
    "\n",
    "# plot classification report\n",
    "best_clf_report_knn = classification_report(y_test,\n",
    "                                   best_predictions,\n",
    "                                   output_dict=True)\n",
    "best_classification_report_knn = sb.heatmap(pd.DataFrame(best_clf_report_knn).iloc[:-1, :].T, annot=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Support Vector Machines"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training time and Accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#create a svm Classifier\n",
    "clf_svm = svm.SVC(kernel='linear') # Linear Kernel\n",
    "\n",
    "#fit the model and time it\n",
    "start = time.time()\n",
    "\n",
    "#train the model using the training sets\n",
    "clf_svm.fit(X_train, y_train)\n",
    "\n",
    "stop = time.time()\n",
    "\n",
    "training_svm = stop - start\n",
    "print(f\"Training: {stop - start} seconds\")\n",
    "\n",
    "#predict the response for test dataset\n",
    "y_pred_svm = clf_svm.predict(X_test)\n",
    "\n",
    "# get accuracy\n",
    "accuracy_svm = accuracy_score(y_test,y_pred_svm)*100\n",
    "print (f\"Accuracy : {accuracy_svm}%\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Confusion Matrix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plot confusion matrix\n",
    "confusion_matrix_svm = sb.heatmap(confusion_matrix(y_test, y_pred_svm),annot=True,cmap='Blues', fmt='g')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Classification Report"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plot classification report\n",
    "clf_report_svm = classification_report(y_test,\n",
    "                                   y_pred_svm,\n",
    "                                   output_dict=True)\n",
    "classification_report_svm = sb.heatmap(pd.DataFrame(clf_report_svm).iloc[:-1, :].T, annot=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Plot"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Plotting our two-features-space\n",
    "sb.scatterplot(x=X_train[:, 0],\n",
    "                y=X_train[:, 1],\n",
    "                hue=y_train,\n",
    "                s=8)\n",
    "\n",
    "# Constructing a hyperplane using a formula.\n",
    "w = clf_svm.coef_[0]           # w consists of 2 elements\n",
    "b = clf_svm.intercept_[0]      # b consists of 1 element\n",
    "x_points = np.linspace(-1, 1)    # generating x-points from -1 to 1\n",
    "y_points = -(w[0] / w[1]) * x_points - b / w[1]  # getting corresponding y-points\n",
    "\n",
    "# Plotting a red hyperplane\n",
    "plt.plot(x_points, y_points, c='r')\n",
    "\n",
    "# Encircle support vectors\n",
    "plt.scatter(clf_svm.support_vectors_[:, 0],\n",
    "            clf_svm.support_vectors_[:, 1],\n",
    "            s=19,\n",
    "            facecolors='none',\n",
    "            edgecolors='k',\n",
    "            alpha=.5)\n",
    "\n",
    "# Step 2 (unit-vector):\n",
    "w_hat = clf_svm.coef_[0] / (np.sqrt(np.sum(clf_svm.coef_[0] ** 2)))\n",
    "\n",
    "# Step 3 (margin):\n",
    "margin = 1 / np.sqrt(np.sum(clf_svm.coef_[0] ** 2))\n",
    "\n",
    "# Step 4 (calculate points of the margin lines):\n",
    "decision_boundary_points = np.array(list(zip(x_points, y_points)))\n",
    "points_of_line_above = decision_boundary_points + w_hat * margin\n",
    "points_of_line_below = decision_boundary_points - w_hat * margin\n",
    "\n",
    "# Plot margin lines# Blue margin line above\n",
    "plt.plot(points_of_line_above[:, 0],\n",
    "         points_of_line_above[:, 1],\n",
    "         'b--',\n",
    "         linewidth=2)\n",
    "\n",
    "# Green margin line below\n",
    "plt.plot(points_of_line_below[:, 0],\n",
    "         points_of_line_below[:, 1],\n",
    "         'g--',\n",
    "         linewidth=2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Stochastic Gradient Descent"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#create a svm Classifier\n",
    "clf_sgc = SGDClassifier(loss=\"hinge\", penalty=\"l2\", max_iter=100)\n",
    "\n",
    "#fit the model and time it\n",
    "start = time.time()\n",
    "\n",
    "#train the model using the training sets\n",
    "clf_sgc.fit(X_train, y_train)\n",
    "\n",
    "stop = time.time()\n",
    "\n",
    "training_sgc = stop - start\n",
    "print(f\"Training: {stop - start} seconds\")\n",
    "\n",
    "#predict the response for test dataset\n",
    "y_pred_sgc = clf_svm.predict(X_test)\n",
    "\n",
    "# get accuracy\n",
    "accuracy_sgc = accuracy_score(y_test,y_pred_sgc)*100\n",
    "print (f\"Accuracy : {accuracy_sgc}%\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Neural Network - Multi-layer Perceptron"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#create a svm Classifier\n",
    "clf_mlp = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), max_iter = 1000)\n",
    "\n",
    "#fit the model and time it\n",
    "start = time.time()\n",
    "\n",
    "#train the model using the training sets\n",
    "clf_mlp.fit(X_train, y_train)\n",
    "\n",
    "stop = time.time()\n",
    "\n",
    "training_mlp = stop - start\n",
    "print(f\"Training: {stop - start} seconds\")\n",
    "\n",
    "#predict the response for test dataset\n",
    "y_pred_mlp = clf_mlp.predict(X_test)\n",
    "\n",
    "# get accuracy\n",
    "accuracy_mlp = accuracy_score(y_test,y_pred_mlp)*100\n",
    "print (f\"Accuracy : {accuracy_mlp}%\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Algorithm Comparison\n",
    "* After testing all algorithms, we compared teh results of all of them, in order to find out which one was the best."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "names = [\"Decision Tree - Gini\", \"Decision Tree - Entropy\", \"Linear SVM\", \"K-Nearest Neighbors\", \"Neural Net\", \"Stochastic Gradient Descent\"]\n",
    "\n",
    "classifiers = [clf_gini, clf_entropy, clf_svm, best_clf_knn, clf_mlp, clf_sgc]\n",
    "\n",
    "X = churn_data.values\n",
    "y = churn_target.values\n",
    "\n",
    "X = StandardScaler().fit_transform(X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "h = 0.2\n",
    "x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "figure = plt.figure(figsize=(27, 9))\n",
    "i=1\n",
    "\n",
    "cm = plt.cm.RdBu\n",
    "cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n",
    "ax = plt.subplot(1, len(classifiers) + 1, i)\n",
    "ax.set_title(\"Input data\")\n",
    "\n",
    "ax.scatter(X_train[:, 0], X_train[:, 1], cmap=cm_bright, edgecolors='k')\n",
    "\n",
    "ax.scatter(X_test[:, 0], X_test[:, 1], cmap=cm_bright, alpha=0.6, edgecolors='k')\n",
    "\n",
    "ax.set_xlim(xx.min(), xx.max())\n",
    "ax.set_ylim(yy.min(), yy.max())\n",
    "ax.set_xticks(())\n",
    "ax.set_yticks(())\n",
    "\n",
    "i += 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for name, clf in zip(names, classifiers):\n",
    "    ax = plt.subplot(1, len(classifiers) + 1, i)\n",
    "    clf.fit(X_train, y_train)\n",
    "    score = clf.score(X_test, y_test)\n",
    "\n",
    "    # Plot the decision boundary. For that, we will assign a color to each\n",
    "    # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "    if hasattr(clf, \"decision_function\"):\n",
    "        Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "    else:\n",
    "        Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
    "\n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    ax.contourf(xx, yy, Z, cmap=cm, alpha=.8)\n",
    "\n",
    "    # Plot the training points\n",
    "    ax.scatter(X_train[:, 0], X_train[:, 1], cmap=cm_bright, edgecolors='k')\n",
    "    # Plot the testing points\n",
    "    ax.scatter(X_test[:, 0], X_test[:, 1], cmap=cm_bright, edgecolors='k', alpha=0.6)\n",
    "\n",
    "    ax.set_xlim(xx.min(), xx.max())\n",
    "    ax.set_ylim(yy.min(), yy.max())\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "    if i == 0:\n",
    "        ax.set_title(name)\n",
    "    ax.text(xx.max() - .3, yy.min() + .3, ('%.2f' % score).lstrip('0'),\n",
    "            size=15, horizontalalignment='right')\n",
    "    i += 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}